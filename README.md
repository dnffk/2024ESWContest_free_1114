# Embedded_software_Contest_2024

본 작품은 Apple의 최신 플랫폼인 VisionOS의 혼합 현실 기능을 활용한 AR 공포 게임과, 게임과 연결해 몰입감을 극대화 할 수 있는 카메라 형태의 임베디드 장치 구현을 목표로 함.

## 👨‍🏫 프로젝트 소개
"햅틱 컨트롤러를 활용한 VisionOS 기반 혼합 현실 공포게임 제작"

실제 환경을 실시간으로 매핑하여 공포 필터를 적용하여 사용자가 익숙하게 지내던 공간을 공포 게임 속 장소로 변환
사용자는 다양한 귀신들을 찾아 카메라 형태의 장치로 촬영하며, 게임 속 오브젝트들과 청-촉각 상호작용


## ⏲️ 개발 기간 
- 2023.07.1(월) ~ 2023.08.30(금)
- 아이디어 회의
- S/W 및 H/W 설계
- S/W 기능 및 UI 구현
- H/W 기능 구현
- S/W 및 H/W 통신 구현
- H/W 패키징
- 프로젝트 통합
- 데모 테스트 및 결과 보고서 작성
- 최종 제출
  
## 🧑‍🤝‍🧑 개발자 소개 
- **손정훈** : 팀장, 인트로 및 엔딩 기능/UI 구현, TCP 통신 구현
- **전예지** : 햅틱 컨트롤러 설계 및 구현
- **남은솔** : 귀신 오브젝트 기능/UI 구현 및 진동 패턴 생성
- **박주연** : 메인 게임 배경 및 카메라 기능/UI 구현

## 💻 H/W 개발환경
- **개발 도구** : Arduino IDE
- **운영 체제** : Window 11
- **언어** : C
- **개발 보드** : ESP-32

## 💻 S/W 개발환경
- **개발 도구** : Unity, Visual Studio, Xcode
- **운영 체제** : MacOS, VisionOS
- **언어** : C#, Python

## 📌 주요 기능
- **혼합 현실 공포게임**
  - #공간 스캐닝#
    -AR Foundation의 meshing 컴포넌트들을 활용하여 실시간으로 실제 환경을 매핑하여 공포 텍스쳐를 적용
  - #가상 오브젝트 증강#
    - 매핑된 공간 내에 랜덤하게 귀신 오브젝트, 물체를 증강
  - #햅틱 컨트롤러 데이터 기반 가상 오브젝트 상호작용#
    - 햅틱 컨트롤러를 통해 수집한 정보를 기반으로 카메라의 각도(AHRS), 촬영(촬영 버튼), 밝기 조절(조도 센서)를 게임 내에서 변경 및 제어
  - #제스처 인식#
    - Apple Vision Pro에서 사용 가능한 기본 제스처(Pinch, Touch, eye tracking) 기능을 통해 증강된 UI들과 상호작용
    - grip 제스처를 인식하여 카메라를 잡았을 경우 게임 내의 뷰 포트가 사용자 앞에 증강

- **햅틱 컨트롤러**
  - #실시간 사용자 피드백#
    - 게임과의 통신을 통해 피격된 귀신 오브젝트 정보와 진동 패턴을 전달받고 햅틱 컨트롤러의 모터를 구동하여 촉각 피드백 제공
    - 셔터 버튼을 누를 경우 게임 내 카메라의 촬영 기능이 재생되며 햅틱 컨트롤러 내의 모터가 작동
    - 손전등 버튼을 누를 경우 햅틱 컨트롤러의 LED가 작동

  - #실시간 환경 정보 수집#
    - AHRS(각도 측정 센서)를 사용해 햅틱 컨트롤러의 각도를 수집하여 게임 내의 카메라 오브젝트의 각도를 조절
    - 조도 센서(주변 밝기 측정 센서)를 사용하여 실제 환경의 밝기 값을 수집 후 게임 내의 캔버스 알파값을 조절하여 게임 환경 조성
